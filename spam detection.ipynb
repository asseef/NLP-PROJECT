{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"spam.csv\",encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
       "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  \n",
       "6        NaN        NaN  \n",
       "7        NaN        NaN  \n",
       "8        NaN        NaN  \n",
       "9        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1400a0e5370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"v1\",data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate len of each corpus\n",
    "df[\"len\"]=df[\"v2\"].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of spam :  138.8661311914324\n"
     ]
    }
   ],
   "source": [
    "\n",
    "average_length_spam = df[df[\"v1\"]==\"spam\"][\"len\"].mean()\n",
    "\n",
    "print(\"average length of spam : \", average_length_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of ham :  71.02362694300518\n"
     ]
    }
   ],
   "source": [
    "average_length_ham = df[df[\"v1\"]==\"ham\"][\"len\"].mean()\n",
    "\n",
    "print(\"average length of ham : \", average_length_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete duplicates\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5126\n",
       "Unnamed: 3    5159\n",
       "Unnamed: 4    5164\n",
       "len              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nan values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unuseful columns\n",
    "df=df[[\"v1\",\"v2\",\"len\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: x.lower())\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: contractions.fix(x))\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)',' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(corpus_):\n",
    "    \n",
    "    for mot in corpus_.split():\n",
    "        if mot not in stopwords.words('english'):\n",
    "            corpus_=corpus_ + mot\n",
    "        else:\n",
    "            corpus_=corpus_ + \" \"\n",
    "    return corpus_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aBoina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def stemming(corpus):\n",
    "    \n",
    "    corpus_=\"\"\n",
    "    \n",
    "    ps = nltk.stem.porter.PorterStemmer()\n",
    "    for mot in corpus.split():\n",
    "        corpus_=corpus_ + \" \" + ps.stem(mot) + \" \"\n",
    "        \n",
    "    return corpus_\n",
    "\n",
    "def lemmatisation(corpus):\n",
    "    corpus_=\"\"\n",
    "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    for mot in corpus.split():\n",
    "        corpus_=corpus_ + \" \" + lem.lemmatize(mot) + \" \"\n",
    "    return corpus_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: remove_stopwords(x))\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: stemming(x))\n",
    "df[\"v2\"]=df[\"v2\"].apply(lambda x: lemmatisation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#tokenization \n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "\n",
    "X=vectorizer.fit_transform(df[\"v2\"])\n",
    "Y=df[\"v1\"]\n",
    "Y.replace(\"spam\",1,inplace=True)\n",
    "Y.replace(\"ham\",0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9613302397525135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1121\n",
      "           1       0.99      0.72      0.83       172\n",
      "\n",
      "    accuracy                           0.96      1293\n",
      "   macro avg       0.98      0.86      0.90      1293\n",
      "weighted avg       0.96      0.96      0.96      1293\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1120    1]\n",
      " [  49  123]]\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(X_train,y_train)\n",
    "y_pred=RF.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9760247486465584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1121\n",
      "           1       0.97      0.84      0.90       172\n",
      "\n",
      "    accuracy                           0.98      1293\n",
      "   macro avg       0.97      0.92      0.94      1293\n",
      "weighted avg       0.98      0.98      0.98      1293\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1117    4]\n",
      " [  27  145]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred=lg.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9806651198762568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1121\n",
      "           1       0.93      0.92      0.93       172\n",
      "\n",
      "    accuracy                           0.98      1293\n",
      "   macro avg       0.96      0.95      0.96      1293\n",
      "weighted avg       0.98      0.98      0.98      1293\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1110   11]\n",
      " [  14  158]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "MB=MultinomialNB()\n",
    "MB.fit(X_train,y_train)\n",
    "y_pred=MB.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9868522815158546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1121\n",
      "           1       0.99      0.91      0.95       172\n",
      "\n",
      "    accuracy                           0.99      1293\n",
      "   macro avg       0.99      0.96      0.97      1293\n",
      "weighted avg       0.99      0.99      0.99      1293\n",
      "\n",
      "Confusion Matrix: \n",
      " [[1119    2]\n",
      " [  15  157]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#test emsemble methode in order to improve performance by combining differents algorithms\n",
    "\n",
    "estimators = [(\"MB\",MB),(\"RF\",RF),(\"LR\",lg)]\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "print('accuracy %s' % accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check consistency of our final model \n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores= cross_val_score(clf,X,Y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98839458, 0.98742747, 0.98549323, 0.98259188, 0.98644724])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
